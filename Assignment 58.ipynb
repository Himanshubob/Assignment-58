{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a6012b",
   "metadata": {},
   "source": [
    "# Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d63fa",
   "metadata": {},
   "source": [
    "# ans.. KNN algo find the k nearest point of the data set and the new data point go the higst nearest data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01984c1c",
   "metadata": {},
   "source": [
    "# Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789127f0",
   "metadata": {},
   "source": [
    "# Square Root Method: Take square root of the number of samples in the training dataset.\n",
    "# Cross Validation Method: We should also use cross validation to find out the optimal value of K in KNN. ...\n",
    "# Domain Knowledge also plays a vital role while choosing the optimum value of K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e519ca",
   "metadata": {},
   "source": [
    "# Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684abb88",
   "metadata": {},
   "source": [
    "# ans.KNN classifier tout put majority of the point \n",
    "# KNN regression the all K point find the averge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaac42c",
   "metadata": {},
   "source": [
    "# Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b008bdb",
   "metadata": {},
   "source": [
    "# The test data is used to evaluate the performance of the model. The model is tested on the test data by using it to make predictions and comparing these predictions to the actual target values. When training a kNN classifier, it's essential to normalize the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63db9c0c",
   "metadata": {},
   "source": [
    "# Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604f33f",
   "metadata": {},
   "source": [
    "# The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size of your data set must also grow exponentially in order to keep the same density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b8dcc",
   "metadata": {},
   "source": [
    "# Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900ac40",
   "metadata": {},
   "source": [
    "# Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df996e8",
   "metadata": {},
   "source": [
    "# Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b65163",
   "metadata": {},
   "source": [
    "# anss.. the given problem is classification so use the KNN calssifier\n",
    "#  but the given problem is regression is so use the KNN regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d6bed",
   "metadata": {},
   "source": [
    "# Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747d1840",
   "metadata": {},
   "source": [
    "# K-NN is pretty intuitive and simple: K-NN algorithm is very simple to understand and equally easy to implement. ...\n",
    "# K-NN has no assumptions: K-NN is a non-parametric algorithm which means there are assumptions to be met to implement K-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a7cd8",
   "metadata": {},
   "source": [
    "# |Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd2a5d",
   "metadata": {},
   "source": [
    "## Manhattan distance is usually preferred over the more common Euclidean distance when there is high dimensionality in the data. Hamming distance is used to measure the distance between categorical variables, and the Cosine distance metric is mainly used to find the amount of similarity between two data point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f45188",
   "metadata": {},
   "source": [
    "# Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca7cff",
   "metadata": {},
   "source": [
    "# To put it simply, yes, feature scaling is crucial for the KNN algorithm, as it helps in preventing features with larger magnitudes from dominating the distance calculations. Feature scaling is an essential step in the data preprocessing pipeline, especially for distance-based algorithms like the KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc4d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
